{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3404a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27338bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of wind speeds and the number of states\n",
    "wind_speed_range = (0, 50)\n",
    "wind_speed_states = 50\n",
    "wind_speed_interval = (wind_speed_range[1] - wind_speed_range[0]) / wind_speed_states\n",
    "wind_speed_states_list = [wind_speed_range[0] + i * wind_speed_interval for i in range(wind_speed_states)]\n",
    "\n",
    "# Define the range of angles of attack and the number of states\n",
    "angle_range = (-15, 15)\n",
    "angle_states = 30\n",
    "angle_interval = (angle_range[1] - angle_range[0]) / angle_states\n",
    "angle_states_list = [angle_range[0] + i * angle_interval for i in range(angle_states)]\n",
    "\n",
    "# Define the number of actions\n",
    "actions = 3\n",
    "increase_angle = 0\n",
    "decrease_angle = 1\n",
    "keep_angle = 2\n",
    "\n",
    "#define wind speed change\n",
    "wind_speed_change = 1\n",
    "\n",
    "counter = 0 #counts the number of times it takes for algorithm to keep the lift constant within loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fe101bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the table\n",
    "table = []\n",
    "headers = ['Wind Speed', 'Angle', 'Lift', 'Reward', 'counter']\n",
    "table.append(headers)\n",
    "\n",
    "\n",
    "# Define the Q-table and some initial parameters\n",
    "q_table = np.zeros((wind_speed_states, angle_states, actions))\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "epsilon = 0.1\n",
    "# maximum number of episodes\n",
    "max_episodes = 1000\n",
    "\n",
    "# Define the function to calculate the lift of the airfoil\n",
    "def lift(angle_of_attack, wind_speed):\n",
    "    # Calculate the Reynolds number\n",
    "    air_density = 1.225 # kg/m^3 (sea level)\n",
    "    air_viscosity = 1.78e-5 # Ns/m^2 (sea level)\n",
    "    chord_length = 0.15 # m (geometry of the NACA 0015 airfoil)\n",
    "    reynolds_number = wind_speed * chord_length / air_viscosity\n",
    "    \n",
    "    # Calculate the lift coefficient\n",
    "    C_l_alpha = 2 * np.pi / 180\n",
    "    C_l_0 = 0.0060\n",
    "    lift_coefficient = C_l_alpha * angle_of_attack + C_l_0\n",
    "    \n",
    "    # Calculate the lift force\n",
    "    lift_force = 0.5 * lift_coefficient * air_density * wind_speed ** 2 * chord_length\n",
    "    \n",
    "    return lift_force\n",
    "\n",
    "# Define the Q-learning algorithm\n",
    "for episode in range(max_episodes):\n",
    "    # Initialize the state and the lift\n",
    "    current_wind_speed = 20 # m/s\n",
    "    current_angle = 15 # degrees\n",
    "    current_lift = lift(current_angle, current_wind_speed)\n",
    "    counter = 0\n",
    "    # Run the Q-learning algorithm\n",
    "    while True:\n",
    "        counter += 1\n",
    "        # Choose an action based on the Q-table and epsilon-greedy strategy\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "            action = np.random.randint(0, actions)\n",
    "        else:\n",
    "            action = np.argmax(q_table[current_wind_speed][current_angle])\n",
    "        \n",
    "        # Calculate the new lift and the new state\n",
    "        new_angle = current_angle + action\n",
    "        if new_angle < angle_range[0]:\n",
    "             new_angle = angle_range[0]\n",
    "        elif new_angle >= angle_range[1]:\n",
    "             new_angle = angle_range[1] -1\n",
    "                \n",
    "        new_wind_speed = current_wind_speed + wind_speed_change\n",
    "\n",
    "        # Check if the new wind speed is within the range of possible wind speeds\n",
    "        if new_wind_speed < wind_speed_range[0]:\n",
    "            new_wind_speed = wind_speed_range[0]\n",
    "        elif new_wind_speed >= wind_speed_range[1]:\n",
    "            new_wind_speed = wind_speed_range[1] -1\n",
    "\n",
    "        new_lift = lift(new_angle, new_wind_speed)\n",
    "        current_lift = lift(current_angle, current_wind_speed)\n",
    "        \n",
    "        # Define the lift threshold\n",
    "        lift_threshold = 0.01 # 1% of the maximum lift force\n",
    "        reward = -1 if abs(new_lift - current_lift) > lift_threshold else 1\n",
    "        \n",
    "        # Last check for windspeed and angle\n",
    "        if new_wind_speed >= wind_speed_states:\n",
    "            new_wind_speed = wind_speed_states - 1\n",
    "        elif new_wind_speed < 0:\n",
    "            new_wind_speed = 0\n",
    "    \n",
    "        if new_angle >= angle_states:\n",
    "            new_angle = angle_states - 1\n",
    "        elif new_angle < 0:\n",
    "            new_angle = 0\n",
    "            \n",
    "        # Update the Q-table\n",
    "        q_table[current_wind_speed][current_angle][action] = (1 - alpha) * q_table[current_wind_speed][current_angle][action] + alpha * (reward + gamma * np.max(q_table[new_wind_speed][new_angle])) \n",
    "        \n",
    "        # Check if the lift is constant\n",
    "        if abs(new_lift - current_lift) < lift_threshold:\n",
    "            break\n",
    "    \n",
    "        # Update the current state and lift\n",
    "        current_wind_speed = new_wind_speed\n",
    "        current_angle = new_angle\n",
    "        current_lift = new_lift    \n",
    "                \n",
    "    if episode % 10 == 0:\n",
    "            table.append([current_wind_speed, current_angle, current_lift, reward, counter])\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2dc1338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Wind Speed', 'Angle', 'Lift', 'Reward', 'counter'],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30],\n",
       " [49, 14, 109.12507786313746, 1, 30]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7c69cb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mq_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "q_table(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67632b8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m         current_angle \u001b[38;5;241m=\u001b[39m next_angle\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Call the Q-learning function\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[43mq_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_wind_speed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_angle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscount_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexploration_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 17\u001b[0m, in \u001b[0;36mq_learning\u001b[1;34m(current_wind_speed, current_angle, alpha, discount_factor, exploration_rate, num_episodes)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mq_learning\u001b[39m(current_wind_speed, current_angle, alpha, discount_factor, exploration_rate, num_episodes):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_episodes):\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;66;03m# Find the closest index of the current wind speed and angle in the state arrays\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m         wind_speed_state \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mabs(\u001b[43mwind_speed_states_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcurrent_wind_speed\u001b[49m))\u001b[38;5;241m.\u001b[39margmin()\n\u001b[0;32m     18\u001b[0m         angle_state \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mabs(angle_states_list \u001b[38;5;241m-\u001b[39m current_angle))\u001b[38;5;241m.\u001b[39margmin()\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;66;03m# Choose an action using the exploration rate\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the state arrays\n",
    "wind_speed_states_list = [0, 5, 10, 15, 20, 25, 30, 35, 40]\n",
    "angle_states_list = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "\n",
    "# Define the action space\n",
    "actions = [-30, 0, 30]\n",
    "\n",
    "# Define the Q-table\n",
    "q_table = np.zeros((len(wind_speed_states_list), len(angle_states_list), len(actions)))\n",
    "\n",
    "# Define the Q-learning algorithm\n",
    "def q_learning(current_wind_speed, current_angle, alpha, discount_factor, exploration_rate, num_episodes):\n",
    "    for episode in range(num_episodes):\n",
    "        # Find the closest index of the current wind speed and angle in the state arrays\n",
    "        wind_speed_state = (np.abs(wind_speed_states_list - current_wind_speed)).argmin()\n",
    "        angle_state = (np.abs(angle_states_list - current_angle)).argmin()\n",
    "        \n",
    "        # Choose an action using the exploration rate\n",
    "        if np.random.uniform(0, 1) < exploration_rate:\n",
    "            action = np.random.choice(actions)\n",
    "        else:\n",
    "            action = np.argmax(q_table[wind_speed_state][angle_state])\n",
    "        \n",
    "        # Update the Q-table\n",
    "        next_wind_speed, next_angle = wind_model(current_wind_speed, current_angle, action)\n",
    "        wind_speed_next_state = (np.abs(wind_speed_states_list - next_wind_speed)).argmin()\n",
    "        angle_next_state = (np.abs(angle_states_list - next_angle)).argmin()\n",
    "        reward = get_reward(next_wind_speed, next_angle)\n",
    "        q_table[wind_speed_state][angle_state][action] = (1 - alpha) * q_table[wind_speed_state][angle_state][action] + alpha * (reward + discount_factor * np.max(q_table[wind_speed_next_state][angle_next_state]))\n",
    "        \n",
    "        # Update the current wind speed and angle\n",
    "        current_wind_speed = next_wind_speed\n",
    "        current_angle = next_angle\n",
    "\n",
    "# Call the Q-learning function\n",
    "q_learning(current_wind_speed, current_angle, alpha=0.1, discount_factor=0.95, exploration_rate=0.1, num_episodes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d13dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
